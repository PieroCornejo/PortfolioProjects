{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1af99774",
   "metadata": {},
   "source": [
    "# CÓDIGO\n",
    "* Se realizan los siguientes análisis:\n",
    "    * 1.Detección de valores no numéricos \n",
    "    * 2.Remoción de elementos por digestión\n",
    "    * 3.Reemplaza data LD a la mitad\n",
    "    * 4.Convertir PPB o PCT a PPM\n",
    "    * 5.Limpiado de data de nuevo\n",
    "    * 6.Añadir Ln\n",
    "    * 7.Ordenamiento de columnas\n",
    "    * 8.Remoción de outlier 1 y 2\n",
    "    * 9.Separar CSV\n",
    "    * 10.Prueba de normalidad y zscore\n",
    "    * 11.Conversión de valores Ln a base (Paramétrico y no paramétricos)\n",
    "    * 12.Parámetros univariados (Paramétrico y no paramétrico)\n",
    "    * 13.Exportación de shapefiles\n",
    "* Parámetros a escribir:\n",
    "    * La ruta del archivo de entrada (no se recomienda modificar el nombre)\n",
    "    * Número de columna para iniciar el análisis (se recomienda la anterior a los elementos)\n",
    "    * Mantener la columna de dominios como la última (para ello el paso 7)\n",
    "    * Número de decimales\n",
    "    * Modificar la cantidad de figuras por columna y fila en caso de los gráficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a508d078",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Especifica la ruta del archivo Excel (reemplaza 'tu_archivo.xlsx' con el nombre de tu archivo)\n",
    "archivo_excel = \"C:/10mo/1_TESIS 2/1_GEOQUIMICA/0_UNIDO/EXCEL/UNIDO.xlsx\"\n",
    "\n",
    "# Lee el archivo Excel en un DataFrame de pandas\n",
    "df = pd.read_excel(archivo_excel)\n",
    "\n",
    "# Especifica la ruta de salida para el archivo CSV (puedes cambiar el nombre si lo deseas)\n",
    "archivo_csv = \"C:/10mo/1_TESIS 2/1_GEOQUIMICA/0_UNIDO/EXCEL/UNIDO.csv\"\n",
    "\n",
    "# Guarda el DataFrame en un archivo CSV\n",
    "df.to_csv(archivo_csv, index=False)\n",
    "\n",
    "print(f\"Archivo CSV guardado exitosamente en: {archivo_csv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4e1e76",
   "metadata": {},
   "source": [
    "# 1. LEER VALORES NO NUMERICOS\n",
    "* El codigo va a leer si es >,<, nulo o 0\n",
    "* Sumará sus valores para luego dividirlo entre el total de celdas por columna\n",
    "* Eliminará los valores que no cumplan el valor limite\n",
    "* Exportará los valores correctos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c50c85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'C:/10mo/1_TESIS 2/1_GEOQUIMICA/1_DOMINIOS/EXCEL/DOMINIO2.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd21287",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Importa un dataframe de un archivo csv (reemplaza 'tu_archivo.csv' con tu archivo)\n",
    "archivo_csv = \"C:/10mo/1_TESIS 2/1_GEOQUIMICA/0_UNIDO/EXCEL/UNIDO.csv\"\n",
    "df = pd.read_csv(archivo_csv)\n",
    "decimal=int(input(\"Ingrese número de decimales: \"))\n",
    "# 2. Pide el número de la columna desde la cual se iniciará el análisis\n",
    "numero_columna = int(input(f\"Ingrese el número de la columna desde la cual desea iniciar el análisis (0 a {len(df.columns) - 1}): \"))\n",
    "\n",
    "# 3. Pide un valor límite\n",
    "valor_limite = float(input(\"Ingrese el valor límite: \"))\n",
    "\n",
    "# Verifica si el número de columna es válido\n",
    "if 0 <= numero_columna < len(df.columns):\n",
    "    # 4. A los valores que sean 0 se les pone vacío\n",
    "    df.iloc[:, numero_columna:] = df.iloc[:, numero_columna:].replace(0, pd.NA)\n",
    "\n",
    "    # Inicializa una lista para almacenar los resultados que exceden el valor límite\n",
    "    resultados_exceden_limite = []\n",
    "\n",
    "    # 5. Para cada columna, cuenta los valores que inician con \">\", \"<\", que empiecen por alguna letra o vacío\n",
    "    for columna in df.columns[numero_columna:]:\n",
    "        # Filtra los valores que cumplen con las condiciones especificadas\n",
    "        valores_mayor = df[columna].astype(str).str.startswith('>')\n",
    "        valores_menor = df[columna].astype(str).str.startswith('<')\n",
    "        valores_letra = df[columna].astype(str).str[0].str.isalpha()\n",
    "        valores_vacios = df[columna].astype(str).str.strip() == ''\n",
    "\n",
    "        # 6. Muestra los valores por cada columna\n",
    "        print(f\"\\nAnálisis de la columna: {columna}\")\n",
    "        print(f\"Valores que inician con '>': {valores_mayor.sum()}\")\n",
    "        print(f\"Valores que inician con '<': {valores_menor.sum()}\")\n",
    "        print(f\"Valores que empiezan con letra: {valores_letra.sum()}\")\n",
    "        print(f\"Valores vacíos: {valores_vacios.sum()}\")\n",
    "\n",
    "        # 7. Sumar esos valores y dividirlos por el total por cada columna\n",
    "        total_celdas = len(df[columna])\n",
    "        suma_valores = valores_mayor.sum() + valores_menor.sum() + valores_letra.sum() + valores_vacios.sum()\n",
    "        promedio = suma_valores / total_celdas\n",
    "\n",
    "        # 8. Comparar el resultado con el valor límite y mostrar los valores límites por columna que excedan el valor límite\n",
    "        print(f\"Promedio: {promedio:.2f}\")\n",
    "        if promedio > valor_limite:\n",
    "            resultados_exceden_limite.append((columna, promedio))\n",
    "\n",
    "    # Mostrar los resultados que exceden el valor límite en una sección aparte\n",
    "    if resultados_exceden_limite:\n",
    "        print(\"\\nResultados que exceden el valor límite:\")\n",
    "        for resultado in resultados_exceden_limite:\n",
    "            print(f\"Columna: {resultado[0]}, Promedio: {resultado[1]:.2f}\")\n",
    "\n",
    "        # 9. Dar la opción para que escriba qué columnas no quiere eliminar del grupo de columnas que excedieron el límite\n",
    "        columnas_a_mantener = input(\"Escriba los nombres de las columnas que no desea eliminar (separadas por coma): \")\n",
    "        columnas_a_mantener = [col.strip() for col in columnas_a_mantener.split(',')]\n",
    "\n",
    "        # 10. Eliminar las columnas restantes del grupo\n",
    "        columnas_a_eliminar = [col[0] for col in resultados_exceden_limite if col[0] not in columnas_a_mantener]\n",
    "        df = df.drop(columnas_a_eliminar, axis=1)\n",
    "\n",
    "        # 11. Exportar el dataframe con nombre \"DOM_LD\"\n",
    "        df.round(decimal).to_csv('C:/10mo/1_TESIS 2/1_GEOQUIMICA/0_UNIDO/EXCEL/1_DOM_LD.csv', index=False)\n",
    "        print(\"El dataframe ha sido exportado con el nombre '1_DOM_LD.csv'.\")\n",
    "\n",
    "else:\n",
    "    print(\"Número de columna no válido. Por favor, ingrese un número dentro del rango.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bcb600",
   "metadata": {},
   "source": [
    "# 2. Metodos de digestion\n",
    "* Filtra los elementos en función del tipo de digestión que se ha empleado\n",
    "* Permite agregar elementos extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679ecd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Importa un dataframe de un archivo csv (reemplaza 'tu_archivo.csv' con tu archivo)\n",
    "archivo_csv = 'C:/10mo/1_TESIS 2/1_GEOQUIMICA/0_UNIDO/EXCEL/1_DOM_LD.csv'\n",
    "df = pd.read_csv(archivo_csv)\n",
    "\n",
    "# 2. Pide el número de la columna desde la cual se iniciará el análisis\n",
    "numero_columna = int(input(f\"Ingrese el número de la columna desde la cual desea iniciar el análisis (0 a {len(df.columns) - 1}): \"))\n",
    "\n",
    "# 3. Crea listas llamadas AR, 4A, FAAS, SPF y LBF con nombres específicos\n",
    "AR = ['Li', 'Sc', 'Mn', 'Re', 'Cu', 'Au', 'Zn', 'Cd', 'Hg', 'Ga', 'In', 'Tl', 'Pb', 'Bi', 'Sb', 'As', 'Se', 'Te']\n",
    "_4A = ['Na', 'K', 'Rb', 'Cs', 'Be', 'Mg', 'Ca', 'Sr', 'Sc', 'Hf', 'La', 'Ce', 'Mo', 'Pr', 'Mn', 'Re', 'Nd', 'Fe', 'Co', 'Sm', 'Ni', 'Eu', 'Gd', 'Ag', 'Cu', 'Zn', 'Cd', 'Tb', 'Al', 'Ga', 'In', 'Tl', 'Dy', 'Ho', 'Pb', 'P', 'As', 'Sb', 'Bi', 'Er', 'Tm', 'Te', 'Se', 'S', 'Yb', 'Lu']\n",
    "FAAS = ['Ru', 'Os', 'Rh', 'Ir', 'Pd', 'Pt', 'Ag', 'Au']\n",
    "SPF = ['Li', 'Be', 'Ti', 'Zr', 'V', 'Nb', 'Ta', 'Cr', 'W', 'Co', 'Ni', 'B', 'Si', 'Sn']\n",
    "LBF = ['Na', 'K', 'Rb', 'Cs', 'Mg', 'Ca', 'Sr', 'Ba', 'Y', 'Ti', 'Zr', 'Hf', 'La', 'V', 'Nb', 'Ta', 'Ce', 'Pr', 'W', 'Cr', 'Nd', 'Fe', 'Sm', 'Eu', 'Gd', 'Tb', 'Al', 'Dy', 'Ho', 'Sn', 'Si', 'Er', 'P', 'Tm', 'S', 'Yb', 'Lu']\n",
    "\n",
    "# 8. Pida una entrada de texto llamada \"Ensayo\"\n",
    "ensayo = input(\"Ingrese el tipo de ensayo (AR, _4A, FAAS, SPF, LBF): \")\n",
    "\n",
    "# 9. Muestra el nombre de cada columna desde la que se iniciará el análisis\n",
    "print(f\"Nombres de las columnas desde la columna {numero_columna}:\")\n",
    "for i, columna in enumerate(df.columns[numero_columna:]):\n",
    "    print(f\"{i}. {columna}\")\n",
    "\n",
    "# 10. Coincidir la entrada \"Ensayo\" con una de las 5 listas creadas al inicio\n",
    "if ensayo == \"AR\":\n",
    "    lista_ensayo = AR\n",
    "elif ensayo == \"_4A\":\n",
    "    lista_ensayo = _4A\n",
    "elif ensayo == \"FAAS\":\n",
    "    lista_ensayo = FAAS\n",
    "elif ensayo == \"SPF\":\n",
    "    lista_ensayo = SPF\n",
    "elif ensayo == \"LBF\":\n",
    "    lista_ensayo = LBF\n",
    "else:\n",
    "    print(\"Tipo de ensayo no reconocido.\")\n",
    "\n",
    "# 11. Compare los elementos de la lista que cumplía el criterio con las dos primeras letras de los nombres de la columna. Muestre aquellos que no coincidan, sepáralos en una lista aparte\n",
    "columnas_no_coincidentes = [col for col in df.columns[numero_columna:] if col[:2].lower() not in [elem[:2].lower() for elem in lista_ensayo]]\n",
    "\n",
    "print(\"Columnas cuyas dos primeras letras no coinciden con la lista seleccionada:\")\n",
    "for i, col in enumerate(columnas_no_coincidentes):\n",
    "    print(f\"{i}. {col}\")\n",
    "\n",
    "# 12. Dar la opción para que escriba qué columnas no quiere eliminar del grupo de columnas que no eran coincidentes.\n",
    "columnas_a_mantener_str = input(\"Escriba el número de las columnas que no quiere eliminar, separadas por comas (si no desea mantener ninguna, presione Enter): \")\n",
    "if columnas_a_mantener_str:\n",
    "    columnas_a_mantener = [int(col) for col in columnas_a_mantener_str.split(',')]\n",
    "else:\n",
    "    columnas_a_mantener = []\n",
    "\n",
    "# 13. Eliminar las columnas restantes del grupo\n",
    "columnas_a_eliminar = [col for i, col in enumerate(columnas_no_coincidentes) if i not in columnas_a_mantener]\n",
    "df = df.drop(columns=columnas_a_eliminar, axis=1)\n",
    "\n",
    "# 14. Exportar el dataframe con nombre \"DOM_DIG\"\n",
    "df.round(decimal).to_csv('C:/10mo/1_TESIS 2/1_GEOQUIMICA/0_UNIDO/EXCEL/2_DOM_DIG.csv', index=False)\n",
    "\n",
    "print(\"Proceso completado. Se ha exportado el dataframe con nombre '2_DOM_DIG.csv'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bcd59c",
   "metadata": {},
   "source": [
    "# 3. LIMPIAR LD\n",
    "* Reemplaza los valores vacíos o 0 a nulos\n",
    "* Reduce a la mitad los valores con > o <"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4666db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Importar un DataFrame desde un archivo CSV\n",
    "archivo_csv = 'C:/10mo/1_TESIS 2/1_GEOQUIMICA/0_UNIDO/EXCEL/2_DOM_DIG.csv'  # Cambia por el nombre de tu archivo CSV\n",
    "df1 = pd.read_csv(archivo_csv)\n",
    "df = df1.copy()  # Se crea una copia del DataFrame original para no modificarlo directamente\n",
    "\n",
    "decimal = int(input(\"Ingrese número de decimales: \"))\n",
    "\n",
    "# 2. Pide el número de la columna desde la cual se iniciará el análisis\n",
    "columna_inicial = int(input(\"Ingrese el número de la columna desde la cual se iniciará el análisis: \")) - 1\n",
    "\n",
    "# 3. Por cada columna, reemplazar los valores 0 o vacíos a nulo (excluyendo la última columna)\n",
    "def reemplazar_nulos(valor):\n",
    "    return pd.NA if valor == 0 or pd.isna(valor) or (isinstance(valor, str) and (valor.strip() == '' or valor[0].isalpha())) else valor\n",
    "\n",
    "# Aplicar la función a cada elemento del DataFrame excluyendo la última columna\n",
    "df.iloc[:, columna_inicial:-1] = df.iloc[:, columna_inicial:-1].applymap(reemplazar_nulos)\n",
    "\n",
    "# 4. Si hay celdas que empiecen con símbolo \">\" o \"<\", eliminar el símbolo y convertirlo a número\n",
    "#    Luego, reemplazar ese número por su mitad\n",
    "def procesar_celda(valor):\n",
    "    if pd.notna(valor) and isinstance(valor, str) and (valor.startswith('>') or valor.startswith('<')):\n",
    "        numero = float(valor[1:])\n",
    "        return round(numero / 2, decimal)\n",
    "    return valor\n",
    "\n",
    "for columna in df.columns[columna_inicial+1:-1]:\n",
    "    df[columna] = df[columna].map(procesar_celda)\n",
    "\n",
    "df.round(decimal).to_csv('C:/10mo/1_TESIS 2/1_GEOQUIMICA/0_UNIDO/EXCEL/3_DOM_NOLD.csv', index=False)\n",
    "\n",
    "print(\"Proceso completado. Se ha exportado el dataframe con nombre '3_DOM_NOLD.csv'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7718924",
   "metadata": {},
   "source": [
    "# 4. CONVERTIR PPB O PCT A PPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309a50e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'C:/10mo/1_TESIS 2/1_GEOQUIMICA/1_DOMINIOS/EXCEL/DOM_LD.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4efc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Importar un dataframe desde un archivo CSV\n",
    "archivo_csv = 'C:/10mo/1_TESIS 2/1_GEOQUIMICA/0_UNIDO/EXCEL/3_DOM_NOLD.csv'  # Reemplaza con la ruta y nombre de tu archivo CSV\n",
    "dataframe = pd.read_csv(archivo_csv)\n",
    "decimal=int(input(\"Ingrese número de decimales: \"))\n",
    "# 2. Pedir el número de la columna desde la cual se iniciará el análisis\n",
    "inicio_analisis = int(input(\"Ingrese el número de la columna desde la cual se iniciará el análisis: \"))\n",
    "\n",
    "# 3. y 4. Procesar las columnas que terminan en \"ppb\" y \"ppt\"\n",
    "for i in range(inicio_analisis, len(dataframe.columns)):\n",
    "    nombre_columna = dataframe.columns[i]\n",
    "    \n",
    "    if nombre_columna.endswith(\"ppb\"):\n",
    "        # Cambiar el nombre de la columna y dividir por 1000\n",
    "        nuevo_nombre = nombre_columna[:-3] + \"ppm\"\n",
    "        dataframe.rename(columns={nombre_columna: nuevo_nombre}, inplace=True)\n",
    "        dataframe[nuevo_nombre] = round(dataframe[nuevo_nombre] / 1000, decimal)\n",
    "    \n",
    "    elif nombre_columna.endswith(\"pct\"):\n",
    "        # Cambiar el nombre de la columna y dividir por 1000000\n",
    "        nuevo_nombre = nombre_columna[:-3] + \"ppm\"\n",
    "        dataframe.rename(columns={nombre_columna: nuevo_nombre}, inplace=True)\n",
    "        dataframe[nuevo_nombre] = round(dataframe[nuevo_nombre] * 10000, decimal)\n",
    "\n",
    "print(dataframe)\n",
    "# 5. Exportar el dataframe en CSV sin incluir el índice\n",
    "dataframe.round(decimal).to_csv(\"C:/10mo/1_TESIS 2/1_GEOQUIMICA/0_UNIDO/EXCEL/4_DOM_PP.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f097f8",
   "metadata": {},
   "source": [
    "# 5. VOLVER A LIMPIAR LA DATA\n",
    "* Se hace en caso los ppb o pct den valores 0.000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de7ea56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Importa un dataframe de un archivo csv (reemplaza 'tu_archivo.csv' con tu archivo)\n",
    "archivo_csv = \"C:/10mo/1_TESIS 2/1_GEOQUIMICA/0_UNIDO/EXCEL/4_DOM_PP.csv\"\n",
    "df = pd.read_csv(archivo_csv)\n",
    "decimal=int(input(\"Ingrese número de decimales: \"))\n",
    "# 2. Pide el número de la columna desde la cual se iniciará el análisis\n",
    "numero_columna = int(input(f\"Ingrese el número de la columna desde la cual desea iniciar el análisis (0 a {len(df.columns) - 1}): \"))\n",
    "\n",
    "# 3. Pide un valor límite\n",
    "valor_limite = float(input(\"Ingrese el valor límite: \"))\n",
    "\n",
    "# Verifica si el número de columna es válido\n",
    "if 0 <= numero_columna < len(df.columns):\n",
    "    # 4. A los valores que sean 0 se les pone vacío\n",
    "    df.iloc[:, numero_columna:] = df.iloc[:, numero_columna:].replace(0, pd.NA)\n",
    "\n",
    "    # Inicializa una lista para almacenar los resultados que exceden el valor límite\n",
    "    resultados_exceden_limite = []\n",
    "\n",
    "    # 5. Para cada columna, cuenta los valores que inician con \">\", \"<\", que empiecen por alguna letra o vacío\n",
    "    for columna in df.columns[numero_columna:]:\n",
    "        # Filtra los valores que cumplen con las condiciones especificadas\n",
    "        valores_mayor = df[columna].astype(str).str.startswith('>')\n",
    "        valores_menor = df[columna].astype(str).str.startswith('<')\n",
    "        valores_letra = df[columna].astype(str).str[0].str.isalpha()\n",
    "        valores_vacios = df[columna].astype(str).str.strip() == ''\n",
    "\n",
    "        # 6. Muestra los valores por cada columna\n",
    "        print(f\"\\nAnálisis de la columna: {columna}\")\n",
    "        print(f\"Valores que inician con '>': {valores_mayor.sum()}\")\n",
    "        print(f\"Valores que inician con '<': {valores_menor.sum()}\")\n",
    "        print(f\"Valores que empiezan con letra: {valores_letra.sum()}\")\n",
    "        print(f\"Valores vacíos: {valores_vacios.sum()}\")\n",
    "\n",
    "        # 7. Sumar esos valores y dividirlos por el total por cada columna\n",
    "        total_celdas = len(df[columna])\n",
    "        suma_valores = valores_mayor.sum() + valores_menor.sum() + valores_letra.sum() + valores_vacios.sum()\n",
    "        promedio = round(suma_valores / total_celdas,decimal)\n",
    "\n",
    "        # 8. Comparar el resultado con el valor límite y mostrar los valores límites por columna que excedan el valor límite\n",
    "        print(f\"Promedio: {promedio:.2f}\")\n",
    "        if promedio > valor_limite:\n",
    "            resultados_exceden_limite.append((columna, promedio))\n",
    "\n",
    "    # Mostrar los resultados que exceden el valor límite en una sección aparte\n",
    "    if resultados_exceden_limite:\n",
    "        print(\"\\nResultados que exceden el valor límite:\")\n",
    "        for resultado in resultados_exceden_limite:\n",
    "            print(f\"Columna: {resultado[0]}, Promedio: {resultado[1]:.2f}\")\n",
    "\n",
    "        # 9. Dar la opción para que escriba qué columnas no quiere eliminar del grupo de columnas que excedieron el límite\n",
    "        columnas_a_mantener = input(\"Escriba los nombres de las columnas que no desea eliminar (separadas por coma): \")\n",
    "        columnas_a_mantener = [col.strip() for col in columnas_a_mantener.split(',')]\n",
    "\n",
    "        # 10. Eliminar las columnas restantes del grupo\n",
    "        columnas_a_eliminar = [col[0] for col in resultados_exceden_limite if col[0] not in columnas_a_mantener]\n",
    "        df = df.drop(columnas_a_eliminar, axis=1)\n",
    "\n",
    "        # 11. Exportar el dataframe con nombre \"DOM_LD\"\n",
    "        df.round(decimal).to_csv('C:/10mo/1_TESIS 2/1_GEOQUIMICA/0_UNIDO/EXCEL/5_DOM_LIMPIO.csv', index=False)\n",
    "        print(\"El dataframe ha sido exportado con el nombre '5_DOM_LIMPIO.csv'.\")\n",
    "\n",
    "else:\n",
    "    print(\"Número de columna no válido. Por favor, ingrese un número dentro del rango.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2697729",
   "metadata": {},
   "source": [
    "# 6. AÑADIR COLUMNAS LN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e398c185",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Paso 1: Importa un dataframe en csv\n",
    "archivo_csv = 'C:/10mo/1_TESIS 2/1_GEOQUIMICA/0_UNIDO/EXCEL/5_DOM_LIMPIO.csv'  # Reemplaza 'tu_archivo.csv' con el nombre de tu archivo CSV\n",
    "df = pd.read_csv(archivo_csv)\n",
    "decimal=int(input(\"Ingrese número de decimales: \"))\n",
    "# Paso 2: Pide el número de columna desde la cual se hará el análisis hasta la penúltima columna\n",
    "try:\n",
    "    inicio_columna = int(input(\"Ingrese el número de la columna desde la cual se realizará el análisis: \"))\n",
    "except ValueError:\n",
    "    print(\"Por favor, ingrese un número válido.\")\n",
    "\n",
    "# Paso 3: Crea a la derecha de cada columna original una nueva columna con logaritmos neperianos\n",
    "for i in range(inicio_columna, len(df.columns) - 1):\n",
    "    columna_original = df.columns[i]\n",
    "    print(columna_original)\n",
    "    nueva_columna_nombre = \"Ln\" + columna_original\n",
    "    df[nueva_columna_nombre] = np.log(df[columna_original]).round(decimal)\n",
    "\n",
    "# Paso 4: Exporta el dataframe con el nombre \"6_DOM_LN\"\n",
    "nombre_archivo_salida = 'C:/10mo/1_TESIS 2/1_GEOQUIMICA/0_UNIDO/EXCEL/6_DOM_LN.csv'\n",
    "df.round(decimal).to_csv(nombre_archivo_salida, index=False)\n",
    "\n",
    "print(f\"El dataframe con logaritmos neperianos ha sido exportado como '{nombre_archivo_salida}'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f744f7e2",
   "metadata": {},
   "source": [
    "# 7. ORDENAR COLUMNAS\n",
    "* Permite seleccionar las columnas para ponerlas al final\n",
    "* Yo la usé para poner la columna DOM al final (la mayoría del código funciona con la columna de dominio al final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987aeb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Paso 1: Importa un dataframe en csv\n",
    "archivo_csv = 'C:/10mo/1_TESIS 2/1_GEOQUIMICA/0_UNIDO/EXCEL/6_DOM_LN.csv'  # Reemplaza 'tu_archivo.csv' con el nombre de tu archivo CSV\n",
    "df = pd.read_csv(archivo_csv)\n",
    "decimal=int(input(\"Ingrese número de decimales: \"))\n",
    "# Muestra los números y nombres de las columnas actuales\n",
    "print(\"Número de columna - Nombre de columna:\")\n",
    "for i, columna in enumerate(df.columns):\n",
    "    print(f\"{i}: {columna}\")\n",
    "\n",
    "# Paso 2: Seleccionar qué columnas cambiarán de posición por número de columna\n",
    "columnas_a_mover_numeros = input(\"Ingrese los números de columna que desea mover (separados por coma): \").split(',')\n",
    "\n",
    "# Validar que los números de columna ingresados sean válidos\n",
    "try:\n",
    "    columnas_a_mover_numeros = [int(num.strip()) for num in columnas_a_mover_numeros]\n",
    "except ValueError:\n",
    "    print(\"Por favor, ingrese números de columna válidos. Saliendo.\")\n",
    "    exit()\n",
    "\n",
    "columnas_a_mover_validas = [col for col in df.columns if df.columns.get_loc(col) in columnas_a_mover_numeros]\n",
    "\n",
    "if not columnas_a_mover_validas:\n",
    "    print(\"No se ingresaron números de columna válidos. Saliendo.\")\n",
    "    exit()\n",
    "\n",
    "# Mostrar los números y nombres de las columnas que se pueden cambiar de posición\n",
    "print(\"Número de columna - Nombre de columna:\")\n",
    "for i, columna in enumerate(columnas_a_mover_validas):\n",
    "    print(f\"{i}: {columna}\")\n",
    "\n",
    "# Copiar las columnas seleccionadas aparte\n",
    "df_copia = df[columnas_a_mover_validas].copy()\n",
    "\n",
    "# Eliminar las columnas seleccionadas del dataframe original\n",
    "df = df.drop(columns=columnas_a_mover_validas)\n",
    "\n",
    "# Añadir las columnas copiadas al final del dataframe\n",
    "df = pd.concat([df, df_copia], axis=1)\n",
    "\n",
    "# Mostrar el dataframe resultante\n",
    "print(\"\\nDataframe con columnas cambiadas de posición:\")\n",
    "print(df)\n",
    "\n",
    "# Opcional: Exportar el dataframe resultante a un nuevo archivo CSV\n",
    "nombre_archivo_salida = 'C:/10mo/1_TESIS 2/1_GEOQUIMICA/0_UNIDO/EXCEL/7_DOM_PRESEP.csv'\n",
    "df.round(decimal).to_csv(nombre_archivo_salida, index=False)\n",
    "print(f\"\\nEl dataframe modificado ha sido exportado como '{nombre_archivo_salida}'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e4caf8",
   "metadata": {},
   "source": [
    "# CREAR HISTOGRAMAS CON DATA OUTLIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06009758",
   "metadata": {},
   "outputs": [],
   "source": [
    "'C:/10mo/1_TESIS 2/1_GEOQUIMICA/1_DOMINIOS/EXCEL/7_DOM_PRESEP.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af928fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Paso 1: Importar un dataframe en csv\n",
    "archivo_csv = 'C:/10mo/1_TESIS 2/1_GEOQUIMICA/0_UNIDO/EXCEL/8_DOM_OUT5.csv'  # Reemplaza 'tu_archivo.csv' con el nombre de tu archivo CSV\n",
    "df = pd.read_csv(archivo_csv)\n",
    "\n",
    "# Paso 2: Seleccionar desde qué columna se iniciará el análisis\n",
    "try:\n",
    "    inicio_columna = int(input(\"Ingrese el número de la columna desde la cual se iniciará el análisis: \"))\n",
    "except ValueError:\n",
    "    print(\"Por favor, ingrese un número válido.\")\n",
    "\n",
    "# Validar que el número de columna ingresado sea válido\n",
    "if inicio_columna < 0 or inicio_columna >= len(df.columns):\n",
    "    print(\"Número de columna no válido. Saliendo.\")\n",
    "    exit()\n",
    "\n",
    "# Filtrar las columnas a partir del inicio_columna\n",
    "columnas_analisis = df.columns[inicio_columna:]\n",
    "\n",
    "# Paso 3: Seleccionar una columna para hacer histogramas\n",
    "columna_histograma = input(\"Ingrese el nombre de la columna para hacer histogramas: \")\n",
    "\n",
    "# Validar que la columna seleccionada exista en el dataframe\n",
    "if columna_histograma not in df.columns:\n",
    "    print(\"La columna seleccionada no existe en el dataframe. Saliendo.\")\n",
    "    exit()\n",
    "\n",
    "# Obtener valores únicos de la columna de histograma\n",
    "valores_unicos = df[columna_histograma].unique()\n",
    "\n",
    "# Paso 4: Graficar histogramas solo para las columnas no seleccionadas\n",
    "for valor_unico in valores_unicos:\n",
    "    # Filtrar el dataframe por el valor único en la columna de histograma\n",
    "    df_filtrado = df[df[columna_histograma] == valor_unico]\n",
    "\n",
    "    # Crear subplots para cada valor único\n",
    "    fig, axs = plt.subplots(4, 5, figsize=(25, 25))\n",
    "\n",
    "    # Contadores para recorrer las filas y columnas de la matriz\n",
    "    fila_actual = 0\n",
    "    columna_actual = 0\n",
    "    print(valor_unico)\n",
    "    # Crear histograma solo para las columnas no seleccionadas\n",
    "    for columna in columnas_analisis:\n",
    "        if columna != columna_histograma:\n",
    "            ax = axs[fila_actual, columna_actual]\n",
    "            ax.hist(df_filtrado[columna], bins=50, alpha=0.5, label=columna, edgecolor='black', linewidth=2)\n",
    "\n",
    "            # Configurar el título en dos líneas\n",
    "            titulo = f\"{valor_unico}\\n{columna}\"\n",
    "            ax.set_title(titulo, fontsize=14)\n",
    "\n",
    "            ax.set_xlabel(\"Valores\", fontsize=12)\n",
    "            ax.set_ylabel(\"Frecuencia\", fontsize=12)\n",
    "            ax.legend(fontsize=10)\n",
    "\n",
    "            # Actualizar contadores de fila y columna\n",
    "            columna_actual += 1\n",
    "            if columna_actual == 5:\n",
    "                columna_actual = 0\n",
    "                fila_actual += 1\n",
    "\n",
    "    # Ajustar el diseño de los subplots\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7015b2ec",
   "metadata": {},
   "source": [
    "# CREAR QQ PLOT CON DATA OUTLIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece2baa1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Paso 1: Importar un dataframe en csv\n",
    "archivo_csv = 'C:/10mo/1_TESIS 2/1_GEOQUIMICA/0_UNIDO/EXCEL/8_DOM_OUT5.csv'  # Reemplaza 'tu_archivo.csv' con el nombre de tu archivo CSV\n",
    "df = pd.read_csv(archivo_csv)\n",
    "\n",
    "# Paso 2: Seleccionar desde qué columna se iniciará el análisis\n",
    "try:\n",
    "    inicio_columna = int(input(\"Ingrese el número de la columna desde la cual se iniciará el análisis: \"))\n",
    "except ValueError:\n",
    "    print(\"Por favor, ingrese un número válido.\")\n",
    "\n",
    "# Validar que el número de columna ingresado sea válido\n",
    "if inicio_columna < 0 or inicio_columna >= len(df.columns):\n",
    "    print(\"Número de columna no válido. Saliendo.\")\n",
    "    exit()\n",
    "\n",
    "# Filtrar las columnas a partir del inicio_columna\n",
    "columnas_analisis = df.columns[inicio_columna:]\n",
    "\n",
    "# Paso 3: Seleccionar una columna para hacer Q-Q plots\n",
    "columna_qqplot = input(\"Ingrese el nombre de la columna para hacer Q-Q plots: \")\n",
    "\n",
    "# Validar que la columna seleccionada exista en el dataframe\n",
    "if columna_qqplot not in df.columns:\n",
    "    print(\"La columna seleccionada no existe en el dataframe. Saliendo.\")\n",
    "    exit()\n",
    "\n",
    "# Obtener valores únicos de la columna para Q-Q plots\n",
    "valores_unicos = df[columna_qqplot].unique()\n",
    "\n",
    "# Paso 4: Graficar Q-Q plots solo para las columnas no seleccionadas\n",
    "for valor_unico in valores_unicos:\n",
    "    # Filtrar el dataframe por el valor único en la columna para Q-Q plots\n",
    "    df_filtrado = df[df[columna_qqplot] == valor_unico]\n",
    "\n",
    "    # Crear subplots para cada valor único\n",
    "    fig, axs = plt.subplots(5, 5, figsize=(25, 25))\n",
    "\n",
    "    # Contadores para recorrer las filas y columnas de la matriz\n",
    "    fila_actual = 0\n",
    "    columna_actual = 0\n",
    "    print(valor_unico)\n",
    "    # Crear Q-Q plot solo para las columnas no seleccionadas\n",
    "    for columna in columnas_analisis:\n",
    "        if columna != columna_qqplot:\n",
    "            ax = axs[fila_actual, columna_actual]\n",
    "            stats.probplot(df_filtrado[columna], plot=ax, fit=True)\n",
    "\n",
    "            # Configurar el título en dos líneas\n",
    "            titulo = f\"{valor_unico}\\n{columna}\"\n",
    "            ax.set_title(titulo, fontsize=14)\n",
    "\n",
    "            # Actualizar contadores de fila y columna\n",
    "            columna_actual += 1\n",
    "            if columna_actual == 5:\n",
    "                columna_actual = 0\n",
    "                fila_actual += 1\n",
    "\n",
    "    # Ajustar el diseño de los subplots\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d604a6",
   "metadata": {},
   "source": [
    "# CREAR GRÁFICO DE CAJAS Y BIGOTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10905a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Paso 1: Importar un dataframe en csv\n",
    "archivo_csv = 'C:/10mo/1_TESIS 2/1_GEOQUIMICA/0_UNIDO/EXCEL/8_DOM_OUT5.csv'  # Reemplaza 'tu_archivo.csv' con el nombre de tu archivo CSV\n",
    "df = pd.read_csv(archivo_csv)\n",
    "\n",
    "# Paso 2: Seleccionar desde qué columna se iniciará el análisis\n",
    "try:\n",
    "    inicio_columna = int(input(\"Ingrese el número de la columna desde la cual se iniciará el análisis: \"))\n",
    "except ValueError:\n",
    "    print(\"Por favor, ingrese un número válido.\")\n",
    "\n",
    "# Validar que el número de columna ingresado sea válido\n",
    "if inicio_columna < 0 or inicio_columna >= len(df.columns):\n",
    "    print(\"Número de columna no válido. Saliendo.\")\n",
    "    exit()\n",
    "\n",
    "# Filtrar las columnas a partir del inicio_columna\n",
    "columnas_analisis = df.columns[inicio_columna:]\n",
    "\n",
    "# Paso 3: Seleccionar una columna para hacer box plot (eje y)\n",
    "columna_boxplot_y = input(\"Ingrese el nombre de la columna cuyos valores únicos servirán como eje Y en el boxplot: \")\n",
    "\n",
    "# Validar que la columna seleccionada exista en el dataframe\n",
    "if columna_boxplot_y not in df.columns:\n",
    "    print(\"La columna seleccionada no existe en el dataframe. Saliendo.\")\n",
    "    exit()\n",
    "\n",
    "# Paso 4: Crear una lista con las columnas restantes\n",
    "columnas_restantes = list(columnas_analisis[columnas_analisis != columna_boxplot_y])\n",
    "\n",
    "# Paso 5: Crear el boxplot utilizando Seaborn\n",
    "for i in range(len(columnas_restantes)):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.boxplot(x=columnas_restantes[i], y=columna_boxplot_y, data=df)\n",
    "\n",
    "# Configurar el título y etiquetas de ejes\n",
    "    plt.xlabel(columnas_restantes[i], fontsize=14)\n",
    "    plt.ylabel(columna_boxplot_y, fontsize=14)\n",
    "\n",
    "# Mostrar el gráfico\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfc937d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96393c53",
   "metadata": {},
   "source": [
    "# 8. REMOCIÓN DE DATA OUTLIER 1\n",
    "* Se utilizaron los valores extremos de la caja y bigotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd574d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'C:/10mo/1_TESIS 2/1_GEOQUIMICA/1_DOMINIOS/EXCEL/7_DOM_PRESEP.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2778b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Importar un dataframe en csv\n",
    "archivo_csv = 'C:/10mo/1_TESIS 2/1_GEOQUIMICA/0_UNIDO/EXCEL/7_DOM_PRESEP.csv'\n",
    "df = pd.read_csv(archivo_csv)\n",
    "decimal=int(input(\"Ingrese el número de decimales: \"))\n",
    "# 2. Pide el número de columna desde el cual se realizará el análisis\n",
    "num_columna_inicial = int(input(f\"Ingrese el número de columna desde 0 hasta {len(df.columns)-1} para iniciar el análisis: \"))\n",
    "columna_inicial = df.columns[num_columna_inicial]\n",
    "\n",
    "# 3. Pide el nombre de la columna para obtener los valores únicos\n",
    "columna_valores_unicos = input(\"Ingrese el nombre de la columna para obtener los valores únicos: \")\n",
    "\n",
    "# 4. Inicializar diccionario para almacenar resumen de valores eliminados por columna y valor único\n",
    "resumen_valores_eliminados = {}\n",
    "\n",
    "# 5. Obtener valores de rango intercuartil, cuartil 1 y cuartil 3 para las columnas restantes\n",
    "for columna in df.columns[num_columna_inicial:]:\n",
    "    if columna != columna_valores_unicos:\n",
    "        resumen_valores_eliminados[columna] = {\"valor_unico\": [], \"cantidad\": [], \"porcentaje\": []}\n",
    "\n",
    "        for valor_unico in df[columna_valores_unicos].unique():\n",
    "            q1 = round(df[(df[columna_valores_unicos] == valor_unico) & (df[columna].notnull())][columna].quantile(0.25), decimal)\n",
    "            q3 = round(df[(df[columna_valores_unicos] == valor_unico) & (df[columna].notnull())][columna].quantile(0.75), decimal)\n",
    "            iqr = round(q3 - q1, decimal)\n",
    "\n",
    "            # 6. Eliminar del dataframe los valores fuera de los umbrales definidos\n",
    "            valores_menor = round((q1 - 1.5 * iqr), decimal)\n",
    "            valores_mayor = round((q3 + 1.5 * iqr), decimal)\n",
    "\n",
    "            filtro = (df[columna_valores_unicos] == valor_unico) & ((df[columna] < valores_menor) | (df[columna] > valores_mayor))\n",
    "\n",
    "            # Reemplazar los valores fuera de los umbrales con NaN\n",
    "            df.loc[filtro, columna] = None\n",
    "\n",
    "            cantidad_eliminada = filtro.sum()\n",
    "            porcentaje_eliminado = (cantidad_eliminada / df[(df[columna_valores_unicos] == valor_unico) & (df[columna].notnull())][columna].count()) * 100\n",
    "\n",
    "            resumen_valores_eliminados[columna][\"valor_unico\"].append(valor_unico)\n",
    "            resumen_valores_eliminados[columna][\"cantidad\"].append(cantidad_eliminada)\n",
    "            resumen_valores_eliminados[columna][\"porcentaje\"].append(round(porcentaje_eliminado, 2))\n",
    "\n",
    "# 7. Mostrar resumen de la cantidad de valores eliminados y su porcentaje por columna y valor único\n",
    "print(\"\\nResumen de valores eliminados por columna y valor único:\")\n",
    "for columna, valores_eliminados in resumen_valores_eliminados.items():\n",
    "    print(f\"\\nColumna: {columna}\")\n",
    "    for valor_unico, cantidad, porcentaje in zip(valores_eliminados[\"valor_unico\"], valores_eliminados[\"cantidad\"], valores_eliminados[\"porcentaje\"]):\n",
    "        print(f\"Dominio: {valor_unico} - Cantidad Eliminada: {cantidad} valores ({porcentaje}%)\")\n",
    "\n",
    "# 8. Exportar el dataframe modificado a un nuevo archivo CSV\n",
    "archivo_salida = 'C:/10mo/1_TESIS 2/1_GEOQUIMICA/0_UNIDO/EXCEL/8_DOM_OUT1.csv'  # Nombre del nuevo archivo CSV\n",
    "df.round(decimal).to_csv(archivo_salida, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1e1123",
   "metadata": {},
   "source": [
    "# 8.1 REMOCIÓN DE DATA OUTLIER 2\n",
    "* En caso se quiera remover outliers por dominio individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07a8248",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Importar un dataframe en csv\n",
    "archivo_csv = 'C:/10mo/1_TESIS 2/1_GEOQUIMICA/0_UNIDO/EXCEL/8_DOM_OUT4.csv'\n",
    "df = pd.read_csv(archivo_csv)\n",
    "decimal=int(input(\"Ingrese el número de decimales: \"))\n",
    "# 2. Pide el número de columna desde el cual se realizará el análisis\n",
    "num_columna_inicial = int(input(f\"Ingrese el número de columna desde 0 hasta {len(df.columns)-1} para iniciar el análisis: \"))\n",
    "columna_inicial = df.columns[num_columna_inicial]\n",
    "\n",
    "# 3. Pide el nombre de la columna para obtener los valores únicos\n",
    "columna_valores_unicos = input(\"Ingrese el nombre de la columna para obtener los valores únicos: \")\n",
    "\n",
    "# 4. Inicializar diccionario para almacenar resumen de valores eliminados por columna y valor único\n",
    "resumen_valores_eliminados = {}\n",
    "\n",
    "# 5. Obtener valores de rango intercuartil, cuartil 1 y cuartil 3 para las columnas restantes\n",
    "for columna in df.columns[num_columna_inicial:]:\n",
    "    if columna != columna_valores_unicos:\n",
    "        resumen_valores_eliminados[columna] = {\"valor_unico\": [], \"cantidad\": [], \"porcentaje\": []}\n",
    "\n",
    "        for valor_unico in df[columna_valores_unicos].unique():\n",
    "            q1 = round(df[(df[columna_valores_unicos] == valor_unico) & (df[columna].notnull())][columna].quantile(0.25), decimal)\n",
    "            q3 = round(df[(df[columna_valores_unicos] == valor_unico) & (df[columna].notnull())][columna].quantile(0.75), decimal)\n",
    "            iqr = round(q3 - q1, decimal)\n",
    "\n",
    "            # 6. Eliminar del dataframe los valores fuera de los umbrales definidos\n",
    "            valores_menor = round((q1 - 1.5 * iqr), decimal)\n",
    "            valores_mayor = round((q3 + 1.5 * iqr), decimal)\n",
    "\n",
    "            filtro = (df[columna_valores_unicos] == valor_unico) & ((df[columna] < valores_menor) | (df[columna] > valores_mayor))\n",
    "\n",
    "            # Reemplazar los valores fuera de los umbrales con NaN\n",
    "            df.loc[filtro, columna] = None\n",
    "\n",
    "            cantidad_eliminada = filtro.sum()\n",
    "            porcentaje_eliminado = (cantidad_eliminada / df[(df[columna_valores_unicos] == valor_unico) & (df[columna].notnull())][columna].count()) * 100\n",
    "\n",
    "            resumen_valores_eliminados[columna][\"valor_unico\"].append(valor_unico)\n",
    "            resumen_valores_eliminados[columna][\"cantidad\"].append(cantidad_eliminada)\n",
    "            resumen_valores_eliminados[columna][\"porcentaje\"].append(round(porcentaje_eliminado, 2))\n",
    "\n",
    "# 7. Mostrar resumen de la cantidad de valores eliminados y su porcentaje por columna y valor único\n",
    "print(\"\\nResumen de valores eliminados por columna y valor único:\")\n",
    "for columna, valores_eliminados in resumen_valores_eliminados.items():\n",
    "    print(f\"\\nColumna: {columna}\")\n",
    "    for valor_unico, cantidad, porcentaje in zip(valores_eliminados[\"valor_unico\"], valores_eliminados[\"cantidad\"], valores_eliminados[\"porcentaje\"]):\n",
    "        print(f\"Dominio: {valor_unico} - Cantidad Eliminada: {cantidad} valores ({porcentaje}%)\")\n",
    "\n",
    "# 8. Exportar el dataframe modificado a un nuevo archivo CSV\n",
    "archivo_salida = 'C:/10mo/1_TESIS 2/1_GEOQUIMICA/0_UNIDO/EXCEL/8_DOM_OUT5.csv'  # Nombre del nuevo archivo CSV\n",
    "df.round(decimal).to_csv(archivo_salida, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb5bc1e",
   "metadata": {},
   "source": [
    "# 9. SEPARAR CSV SEGÚN LOS DOMINIOS\n",
    "* De aquí en adelante, los códigos se aplicarán por cada dominio indivdual; por ello, es necesario separar en diferentes CSV por cada dominio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bbc7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Paso 1: Importa un dataframe en csv\n",
    "archivo_csv = 'C:/10mo/1_TESIS 2/1_GEOQUIMICA/0_UNIDO/EXCEL/8_DOM_OUT5.csv'  # Reemplaza 'tu_archivo.csv' con el nombre de tu archivo CSV\n",
    "df = pd.read_csv(archivo_csv)\n",
    "decimal=int(input(\"Ingrese el número de decimales: \"))\n",
    "# Paso 2: Seleccionar una columna\n",
    "columna_seleccionada123 = input(\"Ingrese el nombre de la columna que desea seleccionar: \")\n",
    "\n",
    "# Verificar que la columna seleccionada existe en el dataframe\n",
    "if columna_seleccionada123 not in df.columns:\n",
    "    print(\"La columna seleccionada no existe en el dataframe. Saliendo.\")\n",
    "    exit()\n",
    "\n",
    "# Obtener valores únicos de la columna seleccionada\n",
    "valores_unicos123 = df[columna_seleccionada123].unique()\n",
    "\n",
    "# Exportar nuevos CSV en función a los valores únicos de la columna\n",
    "for valor123 in valores_unicos123:\n",
    "    # Filtrar el dataframe por el valor único\n",
    "    df_filtrado = df[df[columna_seleccionada123] == valor123]\n",
    "\n",
    "    # Generar nombre para el nuevo archivo CSV\n",
    "    nombre_archivo_salida = f\"9_{columna_seleccionada123}_{str(valor123)}.csv\"\n",
    "\n",
    "    # Exportar el dataframe filtrado a un nuevo archivo CSV\n",
    "    df_filtrado.to_csv(f\"C:/10mo/1_TESIS 2/1_GEOQUIMICA/0_UNIDO/EXCEL/{nombre_archivo_salida}\", index=False)\n",
    "\n",
    "    print(f\"Archivo '{nombre_archivo_salida}' exportado para el valor '{valor123}'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e660ebe",
   "metadata": {},
   "source": [
    "# 10. Z SCORE Y PRUEBAS DE NORMALIDAD\n",
    "* Se debe aplicar la prueba por cada csv de dominio por separado\n",
    "* Se crean nuevas columnas con valores Zscore\n",
    "* Se aplica las pruebas de Kolmogorov (cantidad de muestras mayor a 30) y Shapiro (cantidad de muestras menor a 30)\n",
    "* Permite añadir otras columnas que no hayan pasado el criterio de ser mayor a 0.05 el p_value\n",
    "* Se crea un dataframe llamado dfZ que contiene los valores Z para usarlos en gráficos Q-Q plot y ver si hay elementos que cumplen con la recta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4746ac69",
   "metadata": {},
   "source": [
    "## 10.1. LISTA DE NOMBRES\n",
    "* Se obtiene una lista que contiene los nombres de cada dominio\n",
    "* Esto con el fin de reemplazar el nombre del archivo en la ruta de importación\n",
    "* No modificar lo que está antes de la variable {b} en el resto del código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5ef695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO MODIFICAR\n",
    "valores_unicos123 = df[columna_seleccionada123].unique()\n",
    "nombres_rutas123=[]\n",
    "nombres_rutas_corchetes123=[]\n",
    "for a in valores_unicos123:\n",
    "    nombres_rutas123.append(a)\n",
    "    nombres_rutas_corchetes123.append(a)\n",
    "print(nombres_rutas123)\n",
    "for b in nombres_rutas123:\n",
    "    print(b)\n",
    "for c in nombres_rutas_corchetes123:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99909f2e",
   "metadata": {},
   "source": [
    "### VERSIÓN AUTOMÁTICA\n",
    "* Importa todos los archivos automáticamente\n",
    "* Si te equivocas en insertar los parámetros, no se puede corregir\n",
    "* En caso falten algunos archivos y no quieras volver a escribir todo, hay una versión individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bfea98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "from scipy.stats import kstest, shapiro\n",
    "\n",
    "for b in nombres_rutas123:\n",
    "\n",
    "    # 1. Importar un CSV\n",
    "    archivo_csv = f\"C:/10mo/1_TESIS 2/1_GEOQUIMICA/0_AG/EXCEL/9_DOM_{b}.csv\"\n",
    "    df1 = pd.read_csv(archivo_csv)\n",
    "    print(f\"Se está leyendo el archivo {archivo_csv}\")\n",
    "    df = df1.copy()\n",
    "    decimal = int(input(\"Ingrese el número de decimales: \"))\n",
    "    dom = input(\"Ingrese el nombre de columna de sus dominios: \")\n",
    "    valores_unicos1 = df1[dom].unique()\n",
    "    # 2. Pedir el número de la columna para iniciar el análisis (excluyendo la última columna)\n",
    "    num_columna_inicio = int(input(\"Ingrese el número de la columna a partir del cual iniciará el análisis: \"))\n",
    "    elementos_noZ = df[df.columns[:num_columna_inicio]]  # Excluyendo la última columna\n",
    "    elementos_noZ2 = df[df.columns[num_columna_inicio: - 1]]\n",
    "    \n",
    "    # 3. Por cada columna, transformar a z score y copiar en una nueva columna\n",
    "    for i in range(num_columna_inicio, len(df.columns) - 1):  # Excluyendo la última columna\n",
    "        columna_actual = df.columns[i]\n",
    "        z_scores = (df[columna_actual] - np.mean(df[columna_actual])) / np.std(df[columna_actual])\n",
    "        nombre_nueva_columna = \"Z_\" + columna_actual\n",
    "        df[nombre_nueva_columna] = z_scores\n",
    "    \n",
    "    print(df)\n",
    "    dfZ = df.copy()\n",
    "    # 5. Solo a las columnas cuyo nombre inicie con \"Z_\", aplicar la prueba de normalidad\n",
    "    cumplieron7 = []\n",
    "    for columna in df.columns:\n",
    "        if columna.startswith(\"Z_\"):\n",
    "            num_values = df[columna].dropna()\n",
    "            print(columna)\n",
    "            if len(num_values) > 30:\n",
    "                # Aplicar prueba Kolmogorov-Smirnov-Lilliefors\n",
    "                ks_statistic, ks_p_value = sm.stats.diagnostic.lilliefors(num_values, 'norm', pvalmethod='approx')\n",
    "                prueba_nombre = 'Kolmogorov-Smirnov-Lilliefors'\n",
    "            else:\n",
    "                # Aplicar prueba Shapiro-Wilk\n",
    "                shapiro_statistic, shapiro_p_value = shapiro(num_values)\n",
    "                ks_statistic, ks_p_value = shapiro_statistic, shapiro_p_value  # Para mostrar en la salida\n",
    "                prueba_nombre = 'Shapiro-Wilk'\n",
    "    \n",
    "            # 6. Mostrar la columna con su respectivo p value\n",
    "            print(f\"\\nPrueba de normalidad para {columna} utilizando {prueba_nombre}:\")\n",
    "            print(f\"{prueba_nombre} Statistic: {ks_statistic}\")\n",
    "            print(f\"P Value: {ks_p_value:.3f}\")\n",
    "    \n",
    "            # 7. Agrupar las columnas cuyos p value sean mayores a 0.05\n",
    "            if ks_p_value > 0.05:\n",
    "                cumplieron7.append((columna, prueba_nombre, round(ks_p_value, 3)))\n",
    "    \n",
    "    print(\"Elementos que pasaron la condición >0.05\")\n",
    "    for i in range(len(cumplieron7)):\n",
    "        print(f\"{i + 1}. {cumplieron7[i][0][2:]} - {cumplieron7[i][1]} - p_value: {cumplieron7[i][2]}\")\n",
    "    \n",
    "    # 8. Cambiar los nombres de columna de la lista Cumplieron7 quitándoles el prefijo \"Z_\"\n",
    "    for i in range(len(cumplieron7)):\n",
    "        cumplieron7[i] = (cumplieron7[i][0][2:], cumplieron7[i][1], cumplieron7[i][2])\n",
    "    \n",
    "    # 9. Preguntar por las columnas extras\n",
    "    print(\"\\nColumnas disponibles:\")\n",
    "    for i, col in enumerate(elementos_noZ2.columns, 1):\n",
    "        print(f\"{i}. {col}\")\n",
    "    extras = str(input(\"¿Quiere agregar columnas extras normales (S/N)?: \"))\n",
    "    if extras == \"S\":\n",
    "        columnas_extras_indices = input(\"\\nIngrese los números de las columnas extras separados por comas (sin espacios): \").split(',')\n",
    "        columnas_extras = [elementos_noZ2.columns[int(idx) - 1] for idx in columnas_extras_indices]\n",
    "    else:\n",
    "        columnas_extras = []\n",
    "    \n",
    "    # 10. Comparar los nombres de columna de Cumplieron7 con los nombres de columnas de Elementos_noZ y columnas extras\n",
    "    sicumple = [col for col in elementos_noZ2.columns if col in [c[0] for c in cumplieron7] + columnas_extras]\n",
    "    \n",
    "    # 11. En un nuevo DataFrame, unir las columnas que cumplen el criterio\n",
    "    df_cumplen_criterio = pd.concat([elementos_noZ, df[sicumple], df1[dom]], axis=1)\n",
    "    \n",
    "    # 12. En un nuevo DataFrame, unir las columnas que NO cumplen el criterio\n",
    "    df_no_cumplen_criterio = df.loc[:, ~df.columns.isin(sicumple)]\n",
    "    \n",
    "    # Eliminar las columnas que comienzan con \"Z_\" del DataFrame df_no_cumplen_criterio\n",
    "    df_no_cumplen_criterio = df_no_cumplen_criterio.loc[:, ~df_no_cumplen_criterio.columns.str.startswith(\"Z_\")]\n",
    "    \n",
    "    # Imprimir los DataFrames resultantes\n",
    "    print(\"\\nDataFrame de columnas que cumplen el criterio:\")\n",
    "    print(df_cumplen_criterio)\n",
    "    \n",
    "    print(\"\\nDataFrame de columnas que NO cumplen el criterio (sin columnas que comienzan con 'Z_'):\")\n",
    "    print(df_no_cumplen_criterio)\n",
    "    \n",
    "    # 13. Exportar los DataFrames resultantes a CSV\n",
    "    archivo_salida_cumplen = f'C:/10mo/1_TESIS 2/1_GEOQUIMICA/0_AG/EXCEL/10_{valores_unicos1}_NML.csv'\n",
    "    archivo_salida_no_cumplen = f'C:/10mo/1_TESIS 2/1_GEOQUIMICA/0_AG/EXCEL/10_{valores_unicos1}_NPARA.csv'\n",
    "    \n",
    "    df_cumplen_criterio.round(decimal).to_csv(archivo_salida_cumplen, index=False)\n",
    "    df_no_cumplen_criterio.round(decimal).to_csv(archivo_salida_no_cumplen, index=False)\n",
    "    \n",
    "    print(f\"\\nLos DataFrames resultantes han sido exportados a:\\n- {archivo_salida_cumplen}\\n- {archivo_salida_no_cumplen}.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6bff6f",
   "metadata": {},
   "source": [
    "### VERSIÓN INDIVIDUAL\n",
    "* Acá solo debes modificar la ruta del archivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26a89d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "from scipy.stats import kstest, shapiro\n",
    "\n",
    "# 1. Importar un CSV\n",
    "archivo_csv = \"C:/10mo/1_TESIS 2/1_GEOQUIMICA/0_UNIDO/EXCEL/9_DOM_NO.csv\"\n",
    "df1 = pd.read_csv(archivo_csv)\n",
    "df = df1.copy()\n",
    "decimal = int(input(\"Ingrese el número de decimales: \"))\n",
    "dom = input(\"Ingrese el nombre de columna de sus dominios: \")\n",
    "valores_unicos1 = df1[dom].unique()\n",
    "# 2. Pedir el número de la columna para iniciar el análisis (excluyendo la última columna)\n",
    "num_columna_inicio = int(input(\"Ingrese el número de la columna a partir del cual iniciará el análisis: \"))\n",
    "elementos_noZ = df[df.columns[:num_columna_inicio]]  # Excluyendo la última columna\n",
    "elementos_noZ2 = df[df.columns[num_columna_inicio: - 1]]\n",
    "\n",
    "# 3. Por cada columna, transformar a z score y copiar en una nueva columna\n",
    "for i in range(num_columna_inicio, len(df.columns) - 1):  # Excluyendo la última columna\n",
    "    columna_actual = df.columns[i]\n",
    "    z_scores = (df[columna_actual] - np.mean(df[columna_actual])) / np.std(df[columna_actual])\n",
    "    nombre_nueva_columna = \"Z_\" + columna_actual\n",
    "    df[nombre_nueva_columna] = z_scores\n",
    "\n",
    "print(df)\n",
    "dfZ = df.copy()\n",
    "# 5. Solo a las columnas cuyo nombre inicie con \"Z_\", aplicar la prueba de normalidad\n",
    "cumplieron7 = []\n",
    "for columna in df.columns:\n",
    "    if columna.startswith(\"Z_\"):\n",
    "        num_values = df[columna].dropna()\n",
    "        print(columna)\n",
    "        if len(num_values) > 30:\n",
    "            # Aplicar prueba Kolmogorov-Smirnov-Lilliefors\n",
    "            ks_statistic, ks_p_value = sm.stats.diagnostic.lilliefors(num_values, 'norm', pvalmethod='approx')\n",
    "            prueba_nombre = 'Kolmogorov-Smirnov-Lilliefors'\n",
    "        else:\n",
    "            # Aplicar prueba Shapiro-Wilk\n",
    "            shapiro_statistic, shapiro_p_value = shapiro(num_values)\n",
    "            ks_statistic, ks_p_value = shapiro_statistic, shapiro_p_value  # Para mostrar en la salida\n",
    "            prueba_nombre = 'Shapiro-Wilk'\n",
    "\n",
    "        # 6. Mostrar la columna con su respectivo p value\n",
    "        print(f\"\\nPrueba de normalidad para {columna} utilizando {prueba_nombre}:\")\n",
    "        print(f\"{prueba_nombre} Statistic: {ks_statistic}\")\n",
    "        print(f\"P Value: {ks_p_value:.3f}\")\n",
    "\n",
    "        # 7. Agrupar las columnas cuyos p value sean mayores a 0.05\n",
    "        if ks_p_value > 0.05:\n",
    "            cumplieron7.append((columna, prueba_nombre, round(ks_p_value, 3)))\n",
    "\n",
    "print(\"Elementos que pasaron la condición >0.05\")\n",
    "for i in range(len(cumplieron7)):\n",
    "    print(f\"{i + 1}. {cumplieron7[i][0][2:]} - {cumplieron7[i][1]} - p_value: {cumplieron7[i][2]}\")\n",
    "\n",
    "# 8. Cambiar los nombres de columna de la lista Cumplieron7 quitándoles el prefijo \"Z_\"\n",
    "for i in range(len(cumplieron7)):\n",
    "    cumplieron7[i] = (cumplieron7[i][0][2:], cumplieron7[i][1], cumplieron7[i][2])\n",
    "\n",
    "# 9. Preguntar por las columnas extras\n",
    "print(\"\\nColumnas disponibles:\")\n",
    "for i, col in enumerate(elementos_noZ2.columns, 1):\n",
    "    print(f\"{i}. {col}\")\n",
    "extras = str(input(\"¿Quiere agregar columnas extras normales (S/N)?: \"))\n",
    "if extras == \"S\":\n",
    "    columnas_extras_indices = input(\"\\nIngrese los números de las columnas extras separados por comas (sin espacios): \").split(',')\n",
    "    columnas_extras = [elementos_noZ2.columns[int(idx) - 1] for idx in columnas_extras_indices]\n",
    "else:\n",
    "    columnas_extras = []\n",
    "\n",
    "# 10. Comparar los nombres de columna de Cumplieron7 con los nombres de columnas de Elementos_noZ y columnas extras\n",
    "sicumple = [col for col in elementos_noZ2.columns if col in [c[0] for c in cumplieron7] + columnas_extras]\n",
    "\n",
    "# 11. En un nuevo DataFrame, unir las columnas que cumplen el criterio\n",
    "df_cumplen_criterio = pd.concat([elementos_noZ, df[sicumple], df1[dom]], axis=1)\n",
    "\n",
    "# 12. En un nuevo DataFrame, unir las columnas que NO cumplen el criterio\n",
    "df_no_cumplen_criterio = df.loc[:, ~df.columns.isin(sicumple)]\n",
    "\n",
    "# Eliminar las columnas que comienzan con \"Z_\" del DataFrame df_no_cumplen_criterio\n",
    "df_no_cumplen_criterio = df_no_cumplen_criterio.loc[:, ~df_no_cumplen_criterio.columns.str.startswith(\"Z_\")]\n",
    "\n",
    "# Imprimir los DataFrames resultantes\n",
    "print(\"\\nDataFrame de columnas que cumplen el criterio:\")\n",
    "print(df_cumplen_criterio)\n",
    "\n",
    "print(\"\\nDataFrame de columnas que NO cumplen el criterio (sin columnas que comienzan con 'Z_'):\")\n",
    "print(df_no_cumplen_criterio)\n",
    "\n",
    "# 13. Exportar los DataFrames resultantes a CSV\n",
    "archivo_salida_cumplen = f'C:/10mo/1_TESIS 2/1_GEOQUIMICA/0_UNIDO/EXCEL/10_{valores_unicos1}_NML.csv'\n",
    "archivo_salida_no_cumplen = f'C:/10mo/1_TESIS 2/1_GEOQUIMICA/0_UNIDO/EXCEL/10_{valores_unicos1}_NPARA.csv'\n",
    "\n",
    "df_cumplen_criterio.round(decimal).to_csv(archivo_salida_cumplen, index=False)\n",
    "df_no_cumplen_criterio.round(decimal).to_csv(archivo_salida_no_cumplen, index=False)\n",
    "\n",
    "print(f\"\\nLos DataFrames resultantes han sido exportados a:\\n- {archivo_salida_cumplen}\\n- {archivo_salida_no_cumplen}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f13cee",
   "metadata": {},
   "source": [
    "# GRÁFICO Q-Q PLOT A Z VALUES\n",
    "* Se armarán gráficos Q-Q plot a las columnas de Z values para ver si se ajustan a la recta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb28e4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "\n",
    "print(\"Índices de columnas disponibles:\")\n",
    "for i, columna1 in enumerate(dfZ.columns):\n",
    "    print(f\"{i + 1}. {columna1}\")\n",
    "\n",
    "# Paso 2: Seleccionar desde qué columna se iniciará el análisis\n",
    "try:\n",
    "    inicio_columna = int(input(\"Ingrese el número de la columna desde la cual se iniciará el análisis: \"))\n",
    "except ValueError:\n",
    "    print(\"Por favor, ingrese un número válido.\")\n",
    "\n",
    "# Validar que el número de columna ingresado sea válido\n",
    "if inicio_columna < 0 or inicio_columna >= len(dfZ.columns):\n",
    "    print(\"Número de columna no válido. Saliendo.\")\n",
    "    exit()\n",
    "\n",
    "# Filtrar las columnas a partir del inicio_columna\n",
    "columnas_analisis = dfZ.columns[inicio_columna:]\n",
    "\n",
    "# Paso 3: Seleccionar una columna para hacer Q-Q plots\n",
    "columna_qqplot = input(\"Ingrese el nombre de la columna de dominios para hacer Q-Q plots: \")\n",
    "valores_unicos = dfZ[columna_qqplot].unique()\n",
    "    # Crear subplots para cada valor único\n",
    "fig, axs = plt.subplots(6, 6, figsize=(25, 25))\n",
    "\n",
    "    # Contadores para recorrer las filas y columnas de la matriz\n",
    "fila_actual = 0\n",
    "columna_actual = 0\n",
    "\n",
    "    # Crear Q-Q plot solo para las columnas no seleccionadas\n",
    "for columna in columnas_analisis:\n",
    "    if columna != columna_qqplot:\n",
    "        ax = axs[fila_actual, columna_actual]\n",
    "        stats.probplot(dfZ[columna], plot=ax, fit=True)\n",
    "\n",
    "        # Configurar el título en dos líneas\n",
    "        titulo = f\"{valores_unicos}\\n{columna}\"\n",
    "        ax.set_title(titulo, fontsize=14)        \n",
    "        # Actualizar contadores de fila y columna\n",
    "        columna_actual += 1\n",
    "        if columna_actual == 6:\n",
    "            columna_actual = 0\n",
    "            fila_actual += 1\n",
    "\n",
    "    # Ajustar el diseño de los subplots\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90dc4a1",
   "metadata": {},
   "source": [
    "# 11.1. CONVERSIÓN LN - PARAMÉTRICOS\n",
    "* Se debe hacer la conversión tanto para los paramétricos como no paramétricos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbe3313",
   "metadata": {},
   "source": [
    "### VERSIÓN AUTOMÁTICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcc69db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "for c in nombres_rutas_corchetes123:\n",
    "    # 1. Importa un CSV\n",
    "    archivo_csv = f\"C:/10mo/1_TESIS 2/1_GEOQUIMICA/0_AG/EXCEL/10_['{c}']_NML.csv\"\n",
    "    df = pd.read_csv(archivo_csv)\n",
    "    \n",
    "    # 2. Pide el número de la columna para iniciar el análisis\n",
    "    inicio_analisis = int(input(\"Ingrese el número de la columna para iniciar el análisis: \"))\n",
    "    dom = input(\"Ingrese el nombre de columna de sus dominios: \")\n",
    "    valores_unicos2 = df[dom].unique()\n",
    "    # 3. Modificar columnas que comienzan con \"Ln\"\n",
    "    for i in range(inicio_analisis, df.shape[1] - 1):\n",
    "        if df.columns[i].startswith(\"Ln\"):\n",
    "            # Agregar \"C\" al inicio del nombre de la columna\n",
    "            nuevo_nombre_columna = \"C\" + df.columns[i]\n",
    "            df.rename(columns={df.columns[i]: nuevo_nombre_columna}, inplace=True)\n",
    "    \n",
    "            # Aplicar la función exponencial natural a los valores no vacíos y no nulos\n",
    "            df[nuevo_nombre_columna] = df[nuevo_nombre_columna].apply(lambda x: round(math.exp(float(x)), 2) if pd.notnull(x) and x != 0 else x)\n",
    "    \n",
    "    # 4. Mostrar el DataFrame resultante\n",
    "    print(\"\\nDataFrame resultante:\")\n",
    "    print(df)\n",
    "    \n",
    "    # 5. Exportar el DataFrame resultante\n",
    "    nombre_archivo_salida = f\"C:/10mo/1_TESIS 2/1_GEOQUIMICA/0_AG/EXCEL/11_{valores_unicos2}_NOLN_PARA.csv\" \n",
    "    df.to_csv(nombre_archivo_salida, index=False)\n",
    "    \n",
    "    print(f\"\\nEl DataFrame resultante ha sido exportado a {nombre_archivo_salida}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9dc53ce",
   "metadata": {},
   "source": [
    "### VERSIÓN INDIVIDUAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2627d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "# 1. Importa un CSV\n",
    "archivo_csv = \"C:/10mo/1_TESIS 2/1_GEOQUIMICA/0_AG/EXCEL/10_['Volcanosedimentario Terciario']_NML.csv\"\n",
    "df = pd.read_csv(archivo_csv)\n",
    "\n",
    "# 2. Pide el número de la columna para iniciar el análisis\n",
    "inicio_analisis = int(input(\"Ingrese el número de la columna para iniciar el análisis: \"))\n",
    "dom = input(\"Ingrese el nombre de columna de sus dominios: \")\n",
    "valores_unicos2 = df[dom].unique()\n",
    "# 3. Modificar columnas que comienzan con \"Ln\"\n",
    "for i in range(inicio_analisis, df.shape[1] - 1):\n",
    "    if df.columns[i].startswith(\"Ln\"):\n",
    "        # Agregar \"C\" al inicio del nombre de la columna\n",
    "        nuevo_nombre_columna = \"C\" + df.columns[i]\n",
    "        df.rename(columns={df.columns[i]: nuevo_nombre_columna}, inplace=True)\n",
    "\n",
    "        # Aplicar la función exponencial natural a los valores no vacíos y no nulos\n",
    "        df[nuevo_nombre_columna] = df[nuevo_nombre_columna].apply(lambda x: round(math.exp(float(x)), 2) if pd.notnull(x) and x != 0 else x)\n",
    "\n",
    "# 4. Mostrar el DataFrame resultante\n",
    "print(\"\\nDataFrame resultante:\")\n",
    "print(df)\n",
    "\n",
    "# 5. Exportar el DataFrame resultante\n",
    "nombre_archivo_salida = f\"C:/10mo/1_TESIS 2/1_GEOQUIMICA/0_AG/EXCEL/11_{valores_unicos2}_NOLN_PARA.csv\" \n",
    "df.to_csv(nombre_archivo_salida, index=False)\n",
    "\n",
    "print(f\"\\nEl DataFrame resultante ha sido exportado a {nombre_archivo_salida}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4c95db",
   "metadata": {},
   "source": [
    "# 11.2. CONVERSIÓN LN - NO PARAMÉTRICOS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb18a2c",
   "metadata": {},
   "source": [
    "### VERSIÓN AUTOMÁTICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49d9d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "for c in nombres_rutas_corchetes123:\n",
    "\n",
    "    # 1. Importa un CSV\n",
    "    archivo_csv = f\"C:/10mo/1_TESIS 2/1_GEOQUIMICA/0_AG/EXCEL/10_['{c}']_NPARA.csv\"\n",
    "    df = pd.read_csv(archivo_csv)\n",
    "    \n",
    "    # 2. Pide el número de la columna para iniciar el análisis\n",
    "    inicio_analisis = int(input(\"Ingrese el número de la columna para iniciar el análisis: \"))\n",
    "    dom = input(\"Ingrese el nombre de columna de sus dominios: \")\n",
    "    valores_unicos2 = df[dom].unique()\n",
    "    # 3. Modificar columnas que comienzan con \"Ln\"\n",
    "    for i in range(inicio_analisis, df.shape[1] - 1):\n",
    "        if df.columns[i].startswith(\"Ln\"):\n",
    "            # Agregar \"C\" al inicio del nombre de la columna\n",
    "            nuevo_nombre_columna = \"C\" + df.columns[i]\n",
    "            df.rename(columns={df.columns[i]: nuevo_nombre_columna}, inplace=True)\n",
    "    \n",
    "            # Aplicar la función exponencial natural a los valores no vacíos y no nulos\n",
    "            df[nuevo_nombre_columna] = df[nuevo_nombre_columna].apply(lambda x: round(math.exp(float(x)), 2) if pd.notnull(x) and x != 0 else x)\n",
    "    \n",
    "    # 4. Mostrar el DataFrame resultante\n",
    "    print(\"\\nDataFrame resultante:\")\n",
    "    print(df)\n",
    "    \n",
    "    # 5. Exportar el DataFrame resultante\n",
    "    nombre_archivo_salida = f\"C:/10mo/1_TESIS 2/1_GEOQUIMICA/0_AG/EXCEL/11_{valores_unicos2}_NOLN_NPARA.csv\" \n",
    "    df.to_csv(nombre_archivo_salida, index=False)\n",
    "    \n",
    "    print(f\"\\nEl DataFrame resultante ha sido exportado a {nombre_archivo_salida}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ee08dc",
   "metadata": {},
   "source": [
    "### VERSION INDIVIDUAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57862dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "# 1. Importa un CSV\n",
    "archivo_csv = \"C:/10mo/1_TESIS 2/1_GEOQUIMICA/0_AG/EXCEL/10_['Volcanosedimentario Terciario']_NPARA.csv\"\n",
    "df = pd.read_csv(archivo_csv)\n",
    "\n",
    "# 2. Pide el número de la columna para iniciar el análisis\n",
    "inicio_analisis = int(input(\"Ingrese el número de la columna para iniciar el análisis: \"))\n",
    "dom = input(\"Ingrese el nombre de columna de sus dominios: \")\n",
    "valores_unicos2 = df[dom].unique()\n",
    "# 3. Modificar columnas que comienzan con \"Ln\"\n",
    "for i in range(inicio_analisis, df.shape[1] - 1):\n",
    "    if df.columns[i].startswith(\"Ln\"):\n",
    "        # Agregar \"C\" al inicio del nombre de la columna\n",
    "        nuevo_nombre_columna = \"C\" + df.columns[i]\n",
    "        df.rename(columns={df.columns[i]: nuevo_nombre_columna}, inplace=True)\n",
    "\n",
    "        # Aplicar la función exponencial natural a los valores no vacíos y no nulos\n",
    "        df[nuevo_nombre_columna] = df[nuevo_nombre_columna].apply(lambda x: round(math.exp(float(x)), 2) if pd.notnull(x) and x != 0 else x)\n",
    "\n",
    "# 4. Mostrar el DataFrame resultante\n",
    "print(\"\\nDataFrame resultante:\")\n",
    "print(df)\n",
    "\n",
    "# 5. Exportar el DataFrame resultante\n",
    "nombre_archivo_salida = f\"C:/10mo/1_TESIS 2/1_GEOQUIMICA/0_AG/EXCEL/11_{valores_unicos2}_NOLN_NPARA.csv\" \n",
    "df.to_csv(nombre_archivo_salida, index=False)\n",
    "\n",
    "print(f\"\\nEl DataFrame resultante ha sido exportado a {nombre_archivo_salida}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ee60c9",
   "metadata": {},
   "source": [
    "# 12.1. PARÁMETROS UNIVARIADOS NORMALES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8341ba49",
   "metadata": {},
   "source": [
    "### VERSIÓN AUTOMÁTICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b04ce22",
   "metadata": {},
   "outputs": [],
   "source": [
    "## \n",
    "import pandas as pd\n",
    "\n",
    "for c in nombres_rutas_corchetes123:\n",
    "\n",
    "    # 1. Importa un CSV\n",
    "    archivo_csv = f\"C:/10mo/1_TESIS 2/1_GEOQUIMICA/0_AG/EXCEL/11_['{c}']_NOLN_PARA.csv\" \n",
    "    df = pd.read_csv(archivo_csv)\n",
    "    \n",
    "    # 2. Pide el número de la columna para iniciar el análisis\n",
    "    inicio_analisis = int(input(\"Ingrese el número de la columna para iniciar el análisis: \"))\n",
    "    dom = input(\"Ingrese el nombre de columna de sus dominios: \")\n",
    "    valores_unicos3 = df[dom].unique()\n",
    "    # 3. Calcular media y desviación estándar para cada columna\n",
    "    resultados = []\n",
    "    nombres_columnas = []\n",
    "    for i in range(inicio_analisis, df.shape[1] - 1):\n",
    "        columna = df.iloc[:, i]\n",
    "        media = round(columna.mean(), 2)\n",
    "        desviacion_estandar = round(columna.std(), 2)\n",
    "        resultados.append((media, desviacion_estandar))\n",
    "        nombres_columnas.append(df.columns[i])\n",
    "    \n",
    "    # 4. Calcular VF, T1, T2 y T3 por cada columna\n",
    "    resultados_vf_t1_t2_t3 = []\n",
    "    for i, (media, desviacion_estandar) in enumerate(resultados):\n",
    "        vf = media\n",
    "        t1 = media + desviacion_estandar\n",
    "        t2 = media + 2 * desviacion_estandar\n",
    "        t3 = media + 3 * desviacion_estandar\n",
    "        resultados_vf_t1_t2_t3.append((vf, t1, t2, t3))\n",
    "    \n",
    "    # 5. Mostrar VF, T1, T2 y T3 por cada columna con el nombre de la columna\n",
    "    print(\"\\nResultados:\")\n",
    "    for i, (vf, t1, t2, t3) in enumerate(resultados_vf_t1_t2_t3):\n",
    "        nombre_columna = nombres_columnas[i]\n",
    "        print(f\"\\nColumna {nombre_columna} ({inicio_analisis + i + 1}):\")\n",
    "        print(f\"VF: {vf}, T1: {t1}, T2: {t2}, T3: {t3}\")\n",
    "    \n",
    "    # 6. Copiar cada columna y aplicar las condiciones\n",
    "    for i, (vf, t1, t2, t3) in enumerate(resultados_vf_t1_t2_t3):\n",
    "        nombre_columna_copia = f\"ANM_{nombres_columnas[i]}\"\n",
    "        df[nombre_columna_copia] = df.iloc[:, inicio_analisis + i].apply(lambda x: \"Valor de fondo\" if vf <= x < t1 else (\"Anomalia baja\" if t1 <= x < t2 else (\"Anomalia media\" if t2 <= x < t3 else (\"Anomalia alta\" if t3 <= x else \"Muestra\"))))\n",
    "    \n",
    "    # Mostrar el DataFrame resultante\n",
    "    print(\"\\nDataFrame resultante:\")\n",
    "    print(df)\n",
    "    \n",
    "    nombre_archivo_salida = f\"C:/10mo/1_TESIS 2/1_GEOQUIMICA/0_AG/EXCEL/12_{valores_unicos3}_UNIV_PARA.csv\" \n",
    "    df.to_csv(nombre_archivo_salida, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8634133",
   "metadata": {},
   "source": [
    "### VERSIÓN INDIVIDUAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7f475c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Importa un CSV\n",
    "archivo_csv = \"C:/10mo/1_TESIS 2/1_GEOQUIMICA/0_AG/EXCEL/11_['NO']_NOLN_PARA.csv\" \n",
    "df = pd.read_csv(archivo_csv)\n",
    "\n",
    "# 2. Pide el número de la columna para iniciar el análisis\n",
    "inicio_analisis = int(input(\"Ingrese el número de la columna para iniciar el análisis: \"))\n",
    "dom = input(\"Ingrese el nombre de columna de sus dominios: \")\n",
    "valores_unicos3 = df[dom].unique()\n",
    "# 3. Calcular media y desviación estándar para cada columna\n",
    "resultados = []\n",
    "nombres_columnas = []\n",
    "for i in range(inicio_analisis, df.shape[1] - 1):\n",
    "    columna = df.iloc[:, i]\n",
    "    media = round(columna.mean(), 2)\n",
    "    desviacion_estandar = round(columna.std(), 2)\n",
    "    resultados.append((media, desviacion_estandar))\n",
    "    nombres_columnas.append(df.columns[i])\n",
    "\n",
    "# 4. Calcular VF, T1, T2 y T3 por cada columna\n",
    "resultados_vf_t1_t2_t3 = []\n",
    "for i, (media, desviacion_estandar) in enumerate(resultados):\n",
    "    vf = media\n",
    "    t1 = media + desviacion_estandar\n",
    "    t2 = media + 2 * desviacion_estandar\n",
    "    t3 = media + 3 * desviacion_estandar\n",
    "    resultados_vf_t1_t2_t3.append((vf, t1, t2, t3))\n",
    "\n",
    "# 5. Mostrar VF, T1, T2 y T3 por cada columna con el nombre de la columna\n",
    "print(\"\\nResultados:\")\n",
    "for i, (vf, t1, t2, t3) in enumerate(resultados_vf_t1_t2_t3):\n",
    "    nombre_columna = nombres_columnas[i]\n",
    "    print(f\"\\nColumna {nombre_columna} ({inicio_analisis + i + 1}):\")\n",
    "    print(f\"VF: {vf}, T1: {t1}, T2: {t2}, T3: {t3}\")\n",
    "\n",
    "# 6. Copiar cada columna y aplicar las condiciones\n",
    "for i, (vf, t1, t2, t3) in enumerate(resultados_vf_t1_t2_t3):\n",
    "    nombre_columna_copia = f\"ANM_{nombres_columnas[i]}\"\n",
    "    df[nombre_columna_copia] = df.iloc[:, inicio_analisis + i].apply(lambda x: \"Valor de fondo\" if vf <= x < t1 else (\"Anomalia baja\" if t1 <= x < t2 else (\"Anomalia media\" if t2 <= x < t3 else (\"Anomalia alta\" if t3 <= x else \"Muestra\"))))\n",
    "\n",
    "# Mostrar el DataFrame resultante\n",
    "print(\"\\nDataFrame resultante:\")\n",
    "print(df)\n",
    "\n",
    "nombre_archivo_salida = f\"C:/10mo/1_TESIS 2/1_GEOQUIMICA/0_AG/EXCEL/12_{valores_unicos3}_UNIV_PARA.csv\" \n",
    "df.to_csv(nombre_archivo_salida, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77657ee9",
   "metadata": {},
   "source": [
    "# 12.2. PARÁMETROS UNIVARIADOS NO NORMALES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6287432",
   "metadata": {},
   "source": [
    "### VERSIÓN AUTOMÁTICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22159354",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "for c in nombres_rutas_corchetes123:\n",
    "\n",
    "    # 1. Importa un CSV\n",
    "    archivo_csv = f\"C:/10mo/1_TESIS 2/1_GEOQUIMICA/0_AG/EXCEL/11_['{c}']_NOLN_NPARA.csv\" \n",
    "    df = pd.read_csv(archivo_csv)\n",
    "    \n",
    "    # 2. Pide el número de la columna para iniciar el análisis\n",
    "    inicio_analisis = int(input(\"Ingrese el número de la columna para iniciar el análisis: \"))\n",
    "    dom = input(\"Ingrese el nombre de columna de sus dominios: \")\n",
    "    valores_unicos3 = df[dom].unique()\n",
    "    \n",
    "    # 3. Calcular percentiles para VF, T1, T2 y T3 por cada columna\n",
    "    resultados_percentiles = []\n",
    "    nombres_columnas = []\n",
    "    for i in range(inicio_analisis, df.shape[1] - 1):\n",
    "        columna = df.iloc[:, i]\n",
    "        vf = columna.median()  # Percentil 50 (mediana)\n",
    "        t1 = columna.quantile(0.75)  # Percentil 75\n",
    "        t2 = columna.quantile(0.95)  # Percentil 95\n",
    "        t3 = columna.quantile(0.95) * 2  # Doble del Percentil 95\n",
    "        resultados_percentiles.append((vf, t1, t2, t3))\n",
    "        nombres_columnas.append(df.columns[i])\n",
    "    \n",
    "    # 4. Mostrar VF, T1, T2 y T3 por cada columna con el nombre de la columna\n",
    "    print(\"\\nResultados:\")\n",
    "    for i, (vf, t1, t2, t3) in enumerate(resultados_percentiles):\n",
    "        nombre_columna = nombres_columnas[i]\n",
    "        print(f\"\\nColumna {nombre_columna} ({inicio_analisis + i + 1}):\")\n",
    "        print(f\"VF: {vf}, T1: {t1}, T2: {t2}, T3: {t3}\")\n",
    "    \n",
    "    # 5. Copiar cada columna y aplicar las condiciones\n",
    "    for i, (vf, t1, t2, t3) in enumerate(resultados_percentiles):\n",
    "        nombre_columna_copia = f\"ANM_{nombres_columnas[i]}\"\n",
    "        df[nombre_columna_copia] = df.iloc[:, inicio_analisis + i].apply(lambda x: \"Valor de fondo\" if vf <= x < t1 else (\"Anomalia baja\" if t1 <= x < t2 else (\"Anomalia media\" if t2 <= x < t3 else (\"Anomalia alta\" if t3 <= x else \"Muestra\"))))\n",
    "    \n",
    "    # 6. Mostrar el DataFrame resultante\n",
    "    print(\"\\nDataFrame resultante:\")\n",
    "    print(df)\n",
    "    \n",
    "    nombre_archivo_salida = f\"C:/10mo/1_TESIS 2/1_GEOQUIMICA/0_AG/EXCEL/12_{valores_unicos3}_UNIV_NPARA.csv\" \n",
    "    df.to_csv(nombre_archivo_salida, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fe781c",
   "metadata": {},
   "source": [
    "### VERSIÓN INDIVIDUAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c46d879",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Importa un CSV\n",
    "archivo_csv = \"C:/10mo/1_TESIS 2/1_GEOQUIMICA/0_AG/EXCEL/11_['Volcanosedimentario Terciario']_NOLN_NPARA.csv\" \n",
    "df = pd.read_csv(archivo_csv)\n",
    "\n",
    "# 2. Pide el número de la columna para iniciar el análisis\n",
    "inicio_analisis = int(input(\"Ingrese el número de la columna para iniciar el análisis: \"))\n",
    "dom = input(\"Ingrese el nombre de columna de sus dominios: \")\n",
    "valores_unicos3 = df[dom].unique()\n",
    "\n",
    "# 3. Calcular percentiles para VF, T1, T2 y T3 por cada columna\n",
    "resultados_percentiles = []\n",
    "nombres_columnas = []\n",
    "for i in range(inicio_analisis, df.shape[1] - 1):\n",
    "    columna = df.iloc[:, i]\n",
    "    vf = columna.median()  # Percentil 50 (mediana)\n",
    "    t1 = columna.quantile(0.75)  # Percentil 75\n",
    "    t2 = columna.quantile(0.95)  # Percentil 95\n",
    "    t3 = columna.quantile(0.95) * 2  # Doble del Percentil 95\n",
    "    resultados_percentiles.append((vf, t1, t2, t3))\n",
    "    nombres_columnas.append(df.columns[i])\n",
    "\n",
    "# 4. Mostrar VF, T1, T2 y T3 por cada columna con el nombre de la columna\n",
    "print(\"\\nResultados:\")\n",
    "for i, (vf, t1, t2, t3) in enumerate(resultados_percentiles):\n",
    "    nombre_columna = nombres_columnas[i]\n",
    "    print(f\"\\nColumna {nombre_columna} ({inicio_analisis + i + 1}):\")\n",
    "    print(f\"VF: {vf}, T1: {t1}, T2: {t2}, T3: {t3}\")\n",
    "\n",
    "# 5. Copiar cada columna y aplicar las condiciones\n",
    "for i, (vf, t1, t2, t3) in enumerate(resultados_percentiles):\n",
    "    nombre_columna_copia = f\"ANM_{nombres_columnas[i]}\"\n",
    "    df[nombre_columna_copia] = df.iloc[:, inicio_analisis + i].apply(lambda x: \"Valor de fondo\" if vf <= x < t1 else (\"Anomalia baja\" if t1 <= x < t2 else (\"Anomalia media\" if t2 <= x < t3 else (\"Anomalia alta\" if t3 <= x else \"Muestra\"))))\n",
    "\n",
    "# 6. Mostrar el DataFrame resultante\n",
    "print(\"\\nDataFrame resultante:\")\n",
    "print(df)\n",
    "\n",
    "nombre_archivo_salida = f\"C:/10mo/1_TESIS 2/1_GEOQUIMICA/0_AG/EXCEL/12_{valores_unicos3}_UNIV_NPARA.csv\" \n",
    "df.to_csv(nombre_archivo_salida, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68abb0d6",
   "metadata": {},
   "source": [
    "# 13. CREAR Y EXPORTAR SHAPEFILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abafdfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install geopandas\n",
    "!pip install fiona\n",
    "!pip install shapely\n",
    "!pip install pyproj\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342672b5",
   "metadata": {},
   "source": [
    "### VERSIÓN AUTOMÁTICA\n",
    "* modificar la última parte del nombre\n",
    " * NPARA= No paramétrico\n",
    " * PARA= Paramétrico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1492736",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "from pyproj import CRS\n",
    "\n",
    "for c in nombres_rutas_corchetes123:\n",
    "\n",
    "    # 1. Importar un DataFrame desde un archivo CSV\n",
    "    archivo_csv = f\"C:/10mo/1_TESIS 2/1_GEOQUIMICA/0_AG/EXCEL/12_['{c}']_UNIV_PARA.csv\"  # Reemplaza con la ruta de tu archivo CSV\n",
    "    df = pd.read_csv(archivo_csv)\n",
    "    \n",
    "    # 2. Muestra los índices de columnas y pide seleccionar una para ser las coordenadas X\n",
    "    print(\"Índices de columnas disponibles:\")\n",
    "    for i, columna in enumerate(df.columns):\n",
    "        print(f\"{i + 1}. {columna}\")\n",
    "    \n",
    "    indice_x = int(input(\"Seleccione el índice de la columna para las coordenadas X: \")) - 1\n",
    "    columna_x = df.columns[indice_x]\n",
    "    \n",
    "    # 3. Muestra los índices de columnas y pide seleccionar una para ser las coordenadas Y\n",
    "    print(\"\\nÍndices de columnas disponibles:\")\n",
    "    for i, columna in enumerate(df.columns):\n",
    "        print(f\"{i + 1}. {columna}\")\n",
    "    \n",
    "    indice_y = int(input(\"Seleccione el índice de la columna para las coordenadas Y: \")) - 1\n",
    "    columna_y = df.columns[indice_y]\n",
    "    \n",
    "    dom = input(\"Ingrese el nombre de columna de sus dominios: \")\n",
    "    nombre_dominio = df[dom].unique()\n",
    "    \n",
    "    # 4. Pide que escriba el nombre del dominio\n",
    "    crs1=str(input(\"Ingrese el numero de sistema de coordenadas (32717: UTM 17S/ 32718: UTM 18S/ 32719: UTM 19S/4326: WGS84): \"))\n",
    "    crs= str(\"EPSG:\"+ crs1)\n",
    "    # 5. Crea un archivo Shapefile por cada columna que inicie con \"ANM_\"\n",
    "    for columna in df.columns:\n",
    "        if columna.startswith(\"ANM_\"):\n",
    "            nombre_shapefile = columna[4:] + \"_\" + nombre_dominio\n",
    "    \n",
    "            # Crear un GeoDataFrame con las coordenadas X e Y\n",
    "            geometria = [Point(xy) for xy in zip(df[columna_x], df[columna_y])]\n",
    "            gdf = gpd.GeoDataFrame(df, geometry=geometria, crs=crs)  # WGS84\n",
    "    \n",
    "            # Exportar el Shapefile\n",
    "            ruta_shapefile = f\"C:/10mo/1_TESIS 2/1_GEOQUIMICA/0_AG/SHP_P/{nombre_shapefile}.shp\"  # Reemplaza con la ruta de salida\n",
    "            gdf.to_file(ruta_shapefile)\n",
    "    \n",
    "            print(f\"Shapefile '{nombre_shapefile}' exportado exitosamente en {ruta_shapefile}.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38068656",
   "metadata": {},
   "source": [
    "### VERSION INDIVIDUAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21f3692",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "from pyproj import CRS\n",
    "\n",
    "# 1. Importar un DataFrame desde un archivo CSV\n",
    "archivo_csv = \"C:/10mo/1_TESIS 2/1_GEOQUIMICA/2_NORMALIDAD/EXCEL/12_['Volcanosedimentario Terciario']_UNIV_NPARA.csv\"  # Reemplaza con la ruta de tu archivo CSV\n",
    "df = pd.read_csv(archivo_csv)\n",
    "\n",
    "# 2. Muestra los índices de columnas y pide seleccionar una para ser las coordenadas X\n",
    "print(\"Índices de columnas disponibles:\")\n",
    "for i, columna in enumerate(df.columns):\n",
    "    print(f\"{i + 1}. {columna}\")\n",
    "\n",
    "indice_x = int(input(\"Seleccione el índice de la columna para las coordenadas X: \")) - 1\n",
    "columna_x = df.columns[indice_x]\n",
    "\n",
    "# 3. Muestra los índices de columnas y pide seleccionar una para ser las coordenadas Y\n",
    "print(\"\\nÍndices de columnas disponibles:\")\n",
    "for i, columna in enumerate(df.columns):\n",
    "    print(f\"{i + 1}. {columna}\")\n",
    "\n",
    "indice_y = int(input(\"Seleccione el índice de la columna para las coordenadas Y: \")) - 1\n",
    "columna_y = df.columns[indice_y]\n",
    "\n",
    "dom = input(\"Ingrese el nombre de columna de sus dominios: \")\n",
    "nombre_dominio = df[dom].unique()\n",
    "\n",
    "# 4. Pide que escriba el nombre del dominio\n",
    "crs1=str(input(\"Ingrese el numero de sistema de coordenadas (32717: UTM 17S/ 32718: UTM 18S/ 32719: UTM 19S/4326: WGS84): \"))\n",
    "crs= str(\"EPSG:\"+ crs1)\n",
    "# 5. Crea un archivo Shapefile por cada columna que inicie con \"ANM_\"\n",
    "for columna in df.columns:\n",
    "    if columna.startswith(\"ANM_\"):\n",
    "        nombre_shapefile = columna[4:] + \"_\" + nombre_dominio\n",
    "\n",
    "        # Crear un GeoDataFrame con las coordenadas X e Y\n",
    "        geometria = [Point(xy) for xy in zip(df[columna_x], df[columna_y])]\n",
    "        gdf = gpd.GeoDataFrame(df, geometry=geometria, crs=crs)  # WGS84\n",
    "\n",
    "        # Exportar el Shapefile\n",
    "        ruta_shapefile = f\"C:/10mo/1_TESIS 2/1_GEOQUIMICA/2_NOPARAMETRICO/SHP/{nombre_shapefile}.shp\"  # Reemplaza con la ruta de salida\n",
    "        gdf.to_file(ruta_shapefile)\n",
    "\n",
    "        print(f\"Shapefile '{nombre_shapefile}' exportado exitosamente en {ruta_shapefile}.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
